"""
///////////////////////////////////////////////////////
│	
│	Filename:	automate_3_read_gtf.py
│	
│	Input1:		/?		(folder name of HGTector analysis)
│	Input2:		?.txt	(generated by HGTector analysis)
│	Input3:		?.gtf	(path of annotated protein file for your species of interest)
│	Output:		?_HGT.xlsx
│	
│	Description:
│	To generate Excel file with annotations
│	from the HGTector prediction (hgts/<sample>.txt, https://github.com/qiyunlab/HGTector/blob/master/doc/analyze.md)
│	==================================================
│	Authorship:	@cgneo
│	Copyright:	Modified BSD License.
│	Made with love by @cgneo https://github.com/cgneo
│	
///////////////////////////////////////////////////////
"""


"""
│	⬇️ Mandatory:
│	Enter the folder name that contains a subfolder called "hgts" which contains a txt file
"""
#============================================================
folder_name = ""
#============================================================
"""
│	⬇️ Mandatory:
│	Enter the .gtf file path (annotated protein file, avaliable on NCBI) 
│	For example:
│	gtf_path = "GCF_008000775.1_ASM800077v1_genomic.gtf"
"""
#============================================================
gtf_path = ""
#============================================================
"""
│	⬇️ Mandatory:
│	Enter the file name of .txt under the '/hgts' folder (usually has the same pattern has .gtf)
│	For example:
│	HGT_txt_name = "GCF_008000775.1_ASM800077v1_protein.txt"
"""
#============================================================
HGT_txt_name = ""
#============================================================


"""
First, get all HGT predicted proteins:
"""
dict_of_protein_id = dict()
with open(f'./{folder_name}/hgts/{HGT_txt_name}', 'r') as reader1:
    temp = reader1.readlines()
    counter = 0
    for line in temp:
        temp_str = line.split('\t')
        dict_of_protein_id[temp_str[0]] = {'01': ('n/a', 'n/a'), '01-present':True, '02': ('n/a', 'n/a'), '02-present': False}
        counter += 1
    print(len( dict_of_protein_id.keys() ), counter)

#============================================================
"""
Second. read the close, distal scores:
"""
with open(f'./{folder_name}/scores.tsv', 'r') as reader1:
    temp = reader1.readlines()
    counter = 0
    for line in temp:
        temp_str = line.split('\t')
        if temp_str[1] in dict_of_protein_id:
            dict_of_protein_id[temp_str[1]]['01'] = ( temp_str[5], temp_str[6] )
            counter += 1
    print(f'Read close/distal scores for {counter} proteins.')

######################################################################

from collections import defaultdict
import gzip
import pandas as pd
import re

GTF_HEADER  = ['seqname', 'source', 'feature', 'start', 'end', 'score',
               'strand', 'frame']
R_SEMICOLON = re.compile(r'\s*;\s*')
R_COMMA     = re.compile(r'\s*,\s*')
R_KEYVALUE  = re.compile(r'(\s+|\s*=\s*)')

def dataframe(filename):
    """Open an optionally gzipped GTF file and return a pandas.DataFrame.
    """
    # Each column is a list stored as a value in this dict.
    result = defaultdict(list)

    for i, line in enumerate(lines(filename)):
        for key in line.keys():
            # This key has not been seen yet, so set it to None for all
            # previous lines.
            if key not in result:
                result[key] = [None] * i

        # Ensure this row has some value for each column.
        for key in result.keys():
            result[key].append(line.get(key, None))

    return pd.DataFrame(result)

def lines(filename):
    """Open an optionally gzipped GTF file and generate a dict for each line.
    """
    fn_open = gzip.open if filename.endswith('.gz') else open

    with fn_open(filename) as fh:
        for line in fh:
            if line.startswith('#'):
                continue
            else:
                yield parse(line)

def parse(line):
    """Parse a single GTF line and return a dict.
    """
    result = {}

    fields = line.rstrip().split('\t')

    for i, col in enumerate(GTF_HEADER):
        result[col] = _get_value(fields[i])

    # INFO field consists of "key1=value;key2=value;...".
    infos = [x for x in re.split(R_SEMICOLON, fields[8]) if x.strip()]

    for i, info in enumerate(infos, 1):
        # It should be key="value".
        try:
            key, _, value = re.split(R_KEYVALUE, info, 1)
        # But sometimes it is just "value".
        except ValueError:
            key = 'INFO{}'.format(i)
            value = info
        # Ignore the field if there is no value.
        if value:
            result[key] = _get_value(value)

    return result

def _get_value(value):
    if not value:
        return None

    # Strip double and single quotes.
    value = value.strip('"\'')

    # Return a list if the value has a comma.
    if ',' in value:
        value = re.split(R_COMMA, value)
    # These values are equivalent to None.
    elif value in ['', '.', 'NA']:
        return None

    return value

######################################################################
"""
instruction for reading .gtf:
	df = dataframe( ".gtf" )
	...
"""
#============================================================

df = dataframe( gtf_path )

import pandas as pd
output = pd.DataFrame( )
counter = 0
for protein_id in dict_of_protein_id.keys():
    if 'WP_' in protein_id:
        df_temp = df[df["protein_id"]==protein_id].head(1)
        #============================================================
        close_01, distal_01 = dict_of_protein_id[protein_id]['01']
        #close_02, distal_02 = dict_of_protein_id[protein_id]['02']
        #============================================================
        try:
            if dict_of_protein_id[protein_id]['01-present']==True:
                df_temp.insert(17, "Present in Trial 01", True, True)
            else:
                df_temp.insert(17, "Present in Trial 01", False, True)
            df_temp.insert(18, "Close_01", [close_01], True)
            df_temp.insert(19, "Distal_01", [distal_01], True)
            
            df_temp['protein_id'] = [protein_id]
        except:
            print(dict_of_protein_id)
        # concatenate dataframes
        toBeConcatenated = [output, df_temp]
        output = pd.concat(toBeConcatenated)
        #============================================================
        counter += 1

print(output)

output.to_excel(f'{folder_name}_HGT.xlsx')